{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f73cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function declarations\n",
    "\n",
    "# input: path to folder containing data (data_fpath) and the generic file extension of interest (file_ext)\n",
    "# output: list of data files from specified input directory\n",
    "# reference: https://docs.python.org/3/library/glob.html\n",
    "def find_data_files(data_fpath, file_extension):\n",
    "    data_files = glob(data_fpath + file_extension)\n",
    "    data_files.sort()\n",
    "    return data_files\n",
    "\n",
    "# input: list of csv files (csv_files) and the file path extension that specifies its id with (.+?) (id_search_ext)\n",
    "# output: dictionary mapping a .csv file path itendifier to a dataframe containing its contents\n",
    "# reference: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html \n",
    "def create_dataframe_dict(csv_files, id_search_ext):\n",
    "    df_dict = {}\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df_id = re.search(id_search_ext, file).group(1)\n",
    "        df_dict[df_id] = df\n",
    "    return df_dict\n",
    "\n",
    "# input: dictionary mapping an identifier to its dataframe (df_dict), list of reference column names of interest (col_ref_list), and list of new corresponding column names if different (col_name_list) \n",
    "# output: dataframe containing columns of interet, concatenated across all dataframes in input dictionary\n",
    "# reference: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html, https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "def extract_df_subset(df_dict, col_ref_list, col_name_list=None):\n",
    "    if col_name_list == None: col_name_list = col_ref_list\n",
    "    df_subset_result = pd.DataFrame(columns = col_name_list)\n",
    "    for df_id in df_dict:\n",
    "        df = df_dict[df_id]\n",
    "        df_subset = pd.DataFrame()\n",
    "        df_subset[col_name_list] = df[col_ref_list]\n",
    "        df_subset_result = pd.concat([df_subset_result, df_subset])\n",
    "    return df_subset_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable declaration (user input parameters)\n",
    "\n",
    "# path to folder containing data gathered in a single experiment\n",
    "experiment_folder_fpath = '/Users/sarahfisher/Documents/project/data/CSV_FB_20230404'\n",
    "\n",
    "# generic file extension for .csv data files (replace unique identifiers with `*`)\n",
    "csv_file_ext = '/Time_points_dfs_*.csv'\n",
    "\n",
    "# searchable file extension for .csv data file identifiers (replace `*` with `(.+?)`)\n",
    "id_search_ext = '/Time_points_dfs_(.+?).csv'\n",
    "\n",
    "# list of column names of features of interest on .csv files \n",
    "feature_ref_list = ['mean_F_C2','mean_F_C3','area']\n",
    "\n",
    "# list of renamed features of interest for clarity\n",
    "feature_name_list = ['Mean GFP','Mean RFP','Cell Area']\n",
    "\n",
    "# reference name of colummn describing the timestep from .csv data files\n",
    "timestep_ref = 'Time_interval'\n",
    "\n",
    "# renamed column describing the timestep\n",
    "num_cells_name = 'Timestep'\n",
    "\n",
    "# reference (0-indexed) index of the colummn describing the timestep from .csv data files\n",
    "timestep_index = 13\n",
    "\n",
    "# reference name of number of colummn describing the number of cells from .csv data files\n",
    "num_cells_ref = 'Number_cells'\n",
    "\n",
    "# renamed column describing the number of cells\n",
    "num_cells_name = 'Number of Cells'\n",
    "\n",
    "# reference (0-indexed) index of the colummn describing the number of cells from .csv data files\n",
    "num_cells_index = 12\n",
    "\n",
    "# list of matplotlib binning methods used to determine optimal bin edges\n",
    "methods = ['auto', 'fd', 'doane', 'scott', 'stone', 'rice', 'sturges', 'sqrt']\n",
    "\n",
    "# subset of full list of matplotlib binning methods of interest\n",
    "selected_methods = ['sqrt', 'scott', 'sturges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `main()` function declaration\n",
    "\n",
    "# intended use in coordination with `calculation.ipynb` and `plots.ipynb`\n",
    "# requires: global variable declaration (user input parameters) specified above\n",
    "# output: returns None, assigns new global variables: `well_fpath_list`, `experiment_dict`, `feature_df`\n",
    "def main():\n",
    "    \n",
    "    # list of filepaths of .csv files, each containing data from a single well of the experiment\n",
    "    global well_fpath_list\n",
    "    well_fpath_list = find_data_files(experiment_folder_fpath, csv_file_ext)\n",
    "    # debug\n",
    "    print('well_fpath_list:', type(well_fpath_list), '\\n', well_fpath_list)\n",
    "    \n",
    "    # dictionary mapping each well number in the experiment to a dataframe containing its .csv file data contents\n",
    "    global experiment_dict\n",
    "    experiment_dict = create_dataframe_dict(well_fpath_list, id_search_ext)\n",
    "    # debug\n",
    "    print('experiment_dict:', type(experiment_dict), '\\n', experiment_dict)\n",
    "    \n",
    "    # list of all well ids\n",
    "    global well_id_list\n",
    "    well_id_list = list(experiment_dict)\n",
    "    # debug\n",
    "    print('well_id_list:', type(well_id_list), '\\n', well_id_list)\n",
    "    \n",
    "    # list of all timesteps\n",
    "    global timestep_list\n",
    "    timestep_list = list(set(experiment_dict[well_id_list[0]][timestep_ref]))\n",
    "    # debug\n",
    "    print('timestep_list:', type(timestep_list), '\\n', timestep_list)\n",
    "    \n",
    "    # dataframe containing a specified subset of columns, contents concatenated across all wells of the experiment\n",
    "    global feature_df\n",
    "    feature_df = extract_df_subset(experiment_dict, feature_ref_list, feature_name_list)\n",
    "    # debug\n",
    "    print('feature_df:', type(feature_df), '\\n', feature_df)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call to `main()` function\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
