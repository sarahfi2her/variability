{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f73cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module imports\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import scienceplots\n",
    "import csv\n",
    "from kneed import KneeLocator\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c3adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user input parameters\n",
    "\n",
    "# boolean parameter to dictate use of print statements\n",
    "debug = False\n",
    "\n",
    "# git location\n",
    "git_fpath = '/Users/sarahfisher/Documents/project/variability'\n",
    "\n",
    "# path to folder containing data gathered in a single experiment\n",
    "experiment_folder_fpath = '/Users/sarahfisher/Documents/project/data/20230404/CSV_FB_20230404/'\n",
    "\n",
    "# results filepath\n",
    "results_fpath = '/Users/sarahfisher/Documents/project/data/20230404/results/'\n",
    "\n",
    "# temperature filepath\n",
    "temp_fpath = '/Users/sarahfisher/Documents/project/data/20230404/Temp_df.csv'\n",
    "\n",
    "# filepath extension for results related to temperature\n",
    "temperature_ext_fpath = 'temperature_plots/'\n",
    "\n",
    "# filepath extension for results related to bin selection\n",
    "bin_selection_ext = 'bin_selection/'\n",
    "\n",
    "# filepath extension for results related to bin validation\n",
    "bin_validation_ext = 'bin_validation/'\n",
    "\n",
    "# filepath extension for results related to mi calculation \n",
    "mi_calc_ext= 'mi_calculation/'\n",
    "\n",
    "# filepath extension for results related to pairwise mi calculation \n",
    "pairwise_mi_ext = 'pairwise_mi_calculation/'\n",
    "\n",
    "# filepath extension for results related to correlation\n",
    "correlation_ext = 'intrawell_correlation/'\n",
    "\n",
    "# generic file extension for .csv data files (replace unique identifiers with `*`)\n",
    "raw_csv_file_ext = 'Time_points_dfs_*.csv'\n",
    "\n",
    "# searchable file extension for .csv data file identifiers (replace `*` with `(.+?)`)\n",
    "raw_id_search_ext = 'Time_points_dfs_(.+?).csv'\n",
    "\n",
    "# list of column names of features of interest on .csv files \n",
    "feature_ref_list = ['mean_F_C2','mean_F_C3','area']\n",
    "\n",
    "# list of renamed features of interest for clarity\n",
    "feature_name_list = ['gfp','rfp','area']\n",
    "\n",
    "# dictionary mapping each feature name to its corresponding proper name used in figures\n",
    "proper_feature = {'gfp':'GFP', 'rfp':'RFP', 'area':'Area'}\n",
    "\n",
    "# reference name of column describing the temerature from .csv data file\n",
    "temp_ref = 'T_CHIP(celcius)'\n",
    "\n",
    "# reference name of colummn describing the timestep from .csv data files\n",
    "timestep_ref = 'Time_interval'\n",
    "\n",
    "# renamed column describing the timestep\n",
    "timestep_name = 'timestep'\n",
    "\n",
    "# reference name of number of colummn describing the number of cells from .csv data files\n",
    "num_cells_ref = 'Number_cells'\n",
    "\n",
    "# renamed column describing the number of cells\n",
    "num_cells_name = 'ncells'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe77d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function declaration\n",
    "\n",
    "# input: path to .csv file to append to (csv_fpath), list of the row to append to the file (row)\n",
    "# output: None (appends to the specified .csv file)\n",
    "def append_row_csv(csv_fpath, row):\n",
    "    with open(csv_fpath,'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "    return\n",
    "\n",
    "# input: path to folder containing data (data_fpath) and the generic file extension of interest (file_ext)\n",
    "# output: list of data files from specified input directory\n",
    "def find_data_files(data_fpath, file_extension):\n",
    "    data_files = glob(data_fpath + file_extension)\n",
    "    data_files.sort()\n",
    "    return data_files\n",
    "\n",
    "# input: list of csv files (csv_files) and the file path extension that specifies its id with (.+?) (id_search_ext)\n",
    "# output: dictionary mapping a .csv file path itendifier to a dataframe containing its contents\n",
    "def create_dataframe_dict(csv_files, id_search_ext):\n",
    "    df_dict = {}\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df_id = re.search(id_search_ext, file).group(1)\n",
    "        df_dict[df_id] = df\n",
    "    return df_dict\n",
    "\n",
    "# input: dictionary mapping an identifier to its dataframe (df_dict), list of reference column names of interest (col_ref_list), and list of new corresponding column names if different (col_name_list) \n",
    "# output: dataframe containing columns of interet, concatenated across all dataframes in input dictionary\n",
    "def create_df_subset(df_dict, col_ref_list, col_name_list=None):\n",
    "    if col_name_list == None: col_name_list = col_ref_list\n",
    "    df_subset_result = pd.DataFrame(columns = col_name_list)\n",
    "    for df_id in df_dict:\n",
    "        df = df_dict[df_id]\n",
    "        df_subset = pd.DataFrame()\n",
    "        df_subset[col_name_list] = df[col_ref_list]\n",
    "        df_subset_result = pd.concat([df_subset_result, df_subset])\n",
    "    return df_subset_result\n",
    "\n",
    "# input: dictionary and an ordered list of its keys\n",
    "# output: a lost of ordered values corresponding to keys\n",
    "def create_list_from_dict(dictionary, ordered_keys):\n",
    "    res_list = []\n",
    "    for key in ordered_keys:\n",
    "        res_list.append(dictionary[key])\n",
    "    return res_list\n",
    "\n",
    "# input: list of values (old_vals) and a list of values with a range over which the first values should be scales (new_vals)\n",
    "# output: list of scaled input values\n",
    "def scale(old_vals, new_vals):\n",
    "    scaled = [] \n",
    "    old_range = max(old_vals) - min(old_vals)\n",
    "    new_range = max(new_vals) - min(new_vals)\n",
    "    for val in old_vals:\n",
    "        new_val = ( (val - min(old_vals)) / old_range ) * new_range + min(new_vals)\n",
    "        scaled.append(new_val)\n",
    "    return scaled\n",
    "\n",
    "# input: a set of x-values (x), a set of y-values (y), and a number over which they should be averaged (num)\n",
    "# output: averaged x and y values\n",
    "def avg_plot(x, y, num):\n",
    "    if num == 0:\n",
    "        return x, y\n",
    "    x_new = []\n",
    "    y_new = []\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    n = 0\n",
    "    for i in range(len(x)):\n",
    "        x_temp.append(x[i])\n",
    "        y_temp.append(y[i])\n",
    "        n += 1\n",
    "        if n == num:\n",
    "            x_new.append(sum(x_temp)/len(x_temp))\n",
    "            y_new.append(sum(y_temp)/len(y_temp))\n",
    "            x_temp = []\n",
    "            y_temp = []\n",
    "            n = 0\n",
    "    if n != 0:\n",
    "        x_new.append(sum(x_temp)/len(x_temp))\n",
    "        y_new.append(sum(y_temp)/len(y_temp))\n",
    "    return x_new, y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448a26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specialized function declaration\n",
    "\n",
    "# requires: `timestep_list`, `experiment_dict`, `timestep_ref`, `num_cells_ref`\n",
    "# output: dictionary mapping each timestep to a list of number of cells in each well at that timestep\n",
    "def create_ncells_list_dict():\n",
    "    nmeasure_list_dict = {key:[] for key in timestep_list}\n",
    "    ncells_list_dict = {key:[] for key in timestep_list}\n",
    "    for well in experiment_dict:\n",
    "        well_df = experiment_dict[well]\n",
    "        for t in timestep_list:\n",
    "            ncells = (list((well_df.loc[well_df[timestep_ref] == t])[num_cells_ref]))[0]\n",
    "            nmeasure = len(list((well_df.loc[well_df[timestep_ref] == t])[num_cells_ref]))\n",
    "            ncells_list_dict[t].append(ncells)\n",
    "            nmeasure_list_dict[t].append(nmeasure)\n",
    "    return ncells_list_dict, nmeasure_list_dict\n",
    "\n",
    "# requires: `ncells_list_dict`\n",
    "# output: dictionaries mapping each timestep to its corresponding average number of cells and standard deviation in number of cells\n",
    "def create_ncells_dicts():\n",
    "    ncells_avg_dict = {}\n",
    "    ncells_std_dict = {} \n",
    "    nmeasure_min_dict = {}\n",
    "    for t in ncells_list_dict:\n",
    "        ncells_avg_dict[t] = sum(ncells_list_dict[t])/len(ncells_list_dict[t])\n",
    "        ncells_std_dict[t] = np.std(ncells_list_dict[t])\n",
    "        nmeasure_min_dict[t] = min(min(nmeasure_list_dict[t]), min(ncells_list_dict[t]))\n",
    "    return ncells_avg_dict, ncells_std_dict, nmeasure_min_dict\n",
    "\n",
    "# requires: `results_fpath`, `bin_selection_ext`, existence of `*_optimal_bins.csv` files\n",
    "# output: dictionaries mapping each timestep to its corresponding average number of cells and standard deviation in number of cells\n",
    "def create_bin_edges_dict():\n",
    "    optimal_bins_files = find_data_files(results_fpath+bin_selection_ext, '*_optimal_bins.csv')\n",
    "    optimal_bins_dict = create_dataframe_dict(optimal_bins_files, f'{results_fpath}{bin_selection_ext}(.+?)_optimal_bins.csv')\n",
    "    bin_edges_dict = {}\n",
    "    for feature in optimal_bins_dict:\n",
    "        bin_edges_dict[feature] = list(pd.read_csv(optimal_bins_dict[feature])['bin_edges'])[0]\n",
    "    return bin_edges_dict\n",
    "\n",
    "# requires: `temp_series`\n",
    "# output: list of seconds over which experiment was taken\n",
    "def get_temp_secs():\n",
    "    secs = []\n",
    "    for i in range(len(temp_series)):\n",
    "        secs.append(i)\n",
    "    return secs \n",
    "\n",
    "# requires: `nmeasure_min_list`, `temp_series`, `timestep_list`\n",
    "# output: point at which the experiment starts\n",
    "def get_start_plot():\n",
    "    last = 0\n",
    "    for i in range(len(nmeasure_min_list)):\n",
    "        if nmeasure_min_list[i] > 250 and last == 0:\n",
    "            last = i\n",
    "    start_plot = last*(len(temp_series)/len(timestep_list))\n",
    "    return int(start_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0453d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `main()` function declaration\n",
    "\n",
    "# intended use in coordination with ...\n",
    "# requires: module imports and user input parameters specified above\n",
    "# output: returns None, assigns new global variables: `well_fpath_list`, `experiment_dict`, `feature_df`\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # list of filepaths of .csv files, each containing data from a single well of the experiment\n",
    "    global well_fpath_list\n",
    "    well_fpath_list = find_data_files(experiment_folder_fpath, raw_csv_file_ext)\n",
    "    if debug:\n",
    "        print('well_fpath_list:', type(well_fpath_list), '\\n', well_fpath_list)\n",
    "    \n",
    "    # dictionary mapping each well number in the experiment to a dataframe containing its .csv file data contents\n",
    "    global experiment_dict\n",
    "    experiment_dict = create_dataframe_dict(well_fpath_list, raw_id_search_ext)\n",
    "    if debug:\n",
    "        print('experiment_dict:', type(experiment_dict), '\\n', experiment_dict)\n",
    "    \n",
    "    # list of all well ids\n",
    "    global well_id_list\n",
    "    well_id_list = list(experiment_dict)\n",
    "    if debug:\n",
    "        print('well_id_list:', type(well_id_list), '\\n', well_id_list)\n",
    "    \n",
    "    # list of all timesteps\n",
    "    global timestep_list\n",
    "    timestep_list = list(set(experiment_dict[well_id_list[0]][timestep_ref]))\n",
    "    if debug:\n",
    "        print('timestep_list:', type(timestep_list), '\\n', timestep_list)\n",
    "        \n",
    "    # series of recorded temperatures\n",
    "    global temp_series\n",
    "    temp_series = pd.read_csv(temp_fpath)[temp_ref]\n",
    "    if debug:\n",
    "        print('temp_series:', type(temp_series), '\\n', temp_series)\n",
    "        \n",
    "    # list of times at which temperatures were recorded\n",
    "    global temp_secs\n",
    "    temp_secs = get_temp_secs()\n",
    "    if debug:\n",
    "        print('temp_secs:', type(temp_secs), '\\n', temp_secs)\n",
    "        \n",
    "    # list of recorded timesteps scaled to seconds\n",
    "    global timestep_scaled\n",
    "    timestep_scaled = scale(timestep_list, temp_secs)\n",
    "    if debug:\n",
    "        print('timestep_scaled:', type(timestep_scaled), '\\n', timestep_scaled)\n",
    "    \n",
    "    # dataframe containing a specified subset of columns, contents concatenated across all wells of the experiment\n",
    "    global feature_df\n",
    "    feature_df = create_df_subset(experiment_dict, feature_ref_list, feature_name_list)\n",
    "    if debug:\n",
    "        print('feature_df:', type(feature_df), '\\n', feature_df)\n",
    "    \n",
    "    # dictionary mapping a timestep to a list of the number of cells in each well and number of cells measured at that timestep\n",
    "    global ncells_list_dict\n",
    "    global nmeasure_list_dict\n",
    "    ncells_list_dict, nmeasure_list_dict = create_ncells_list_dict()\n",
    "    if debug:\n",
    "        print('ncells_list_dict:', type(ncells_list_dict), '\\n', ncells_list_dict)\n",
    "        print('nmeasure_list_dict:', type(nmeasure_list_dict), '\\n', nmeasure_list_dict)\n",
    "\n",
    "    # dictionary mapping a timestep to the average, standard deviation in number of cells at that timestep\n",
    "    global ncells_avg_dict\n",
    "    global ncells_std_dict\n",
    "    global nmeasure_min_dict\n",
    "    ncells_avg_dict, ncells_std_dict, nmeasure_min_dict = create_ncells_dicts()\n",
    "    if debug:\n",
    "        print('ncells_avg_dict:', type(ncells_avg_dict), ncells_avg_dict)\n",
    "        print('ncells_std_dict:', type(ncells_std_dict), ncells_std_dict)\n",
    "        print('nmeasure_min_dict:', type(nmeasure_min_dict), nmeasure_min_dict)\n",
    "\n",
    "    # list of the average number of cells through time\n",
    "    global ncells_avg_list\n",
    "    ncells_avg_list = create_list_from_dict(ncells_avg_dict, timestep_list)\n",
    "    if debug:\n",
    "        print('ncells_avg_list:', type(ncells_avg_list), '\\n', ncells_avg_list)\n",
    "\n",
    "    # list of the standard deviation in number of cells through time\n",
    "    global ncells_std_list\n",
    "    ncells_std_list = create_list_from_dict(ncells_std_dict, timestep_list)\n",
    "    if debug:\n",
    "        print('ncells_std_list:', type(ncells_std_list), '\\n', ncells_std_list)\n",
    "\n",
    "    # list of the average number of measured cells through time\n",
    "    global nmeasure_min_list\n",
    "    nmeasure_min_list = create_list_from_dict(nmeasure_min_dict, timestep_list)\n",
    "    if debug:\n",
    "        print('nmeasure_min_list:', type(nmeasure_min_list), '\\n', nmeasure_min_list)\n",
    "        \n",
    "    # second mark of experiment where the minimum number of cells measured is 250\n",
    "    global start_plot\n",
    "    start_plot = get_start_plot()\n",
    "    if debug:\n",
    "        print('start_plot:', type(start_plot), '\\n', start_plot)\n",
    "    \n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed654040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call to `main()` function\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
